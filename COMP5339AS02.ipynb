{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ed03c2",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f8fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import csv\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "# For Generate Unique Transaction Id for accesing API\n",
    "import uuid\n",
    "\n",
    "import config_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b52e1f",
   "metadata": {},
   "source": [
    "Import API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c0c5b",
   "metadata": {},
   "source": [
    "Import API Key Instructions\n",
    "\n",
    "1. Go to the [NSW API Fuel documentation](https://api.nsw.gov.au/Product/Index/22#v-pills-doc) to get the **API Key** and **Authorization Header**.  \n",
    "2. Subscribe to the Fuel API by creating an NSW API account:  \n",
    "   - Create a new app with your chosen **App Name** and **App Description**.  \n",
    "   - Under **Add an API Product**, select **Fuel API**.  \n",
    "   - Scroll to the bottom of the page and click **Add app**.  \n",
    "   - You will receive your **API Key**, **API Secret**, and **Authorization Header**.  \n",
    "3. In the home directory of your assignment folder, create a file named `config_secret.py`.  \n",
    "   - _Note:_ Place `config_secret.py` in the same directory as `COMP5339AS02.ipynb`.  \n",
    "4. Open `config_secret.py` and add your `API_KEY` and `AuthorizationHeader`.  \n",
    "   - A sample file has been provided as `config_secret_sample.py`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "920803cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab your key from config_secret.py\n",
    "API_KEY = config_secret.API_KEY\n",
    "AuthorizationHeader = config_secret.AuthorizationHeader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f84373",
   "metadata": {},
   "source": [
    "1. Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db7aaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Retrieval\n",
    "\n",
    "# Fuel API Document\n",
    "# https://api.nsw.gov.au/Product/Index/22#v-pills-doc\n",
    "\n",
    "class FuelPriceCheckAPI:\n",
    "    def __init__(self, API_KEY, AuthorizationHeader):\n",
    "        self.url_base = \"https://api.onegov.nsw.gov.au\" # Base Url\n",
    "        self.API_KEY = API_KEY\n",
    "        self.AuthorizationHeader = AuthorizationHeader\n",
    "\n",
    "    \n",
    "    def get_datetime_now():\n",
    "        return datetime.now(timezone.utc).strftime(\"%d/%m/%Y %I:%M:%S %p\")\n",
    "    \n",
    "\n",
    "    def get_unique_transactionId():\n",
    "        return str(uuid.uuid4())\n",
    "\n",
    "    def get_accesstoken(self):\n",
    "        # Config url api prameters for getting accesstoken\n",
    "        url_subpart = \"/oauth/client_credential/accesstoken\"\n",
    "\n",
    "        url = self.url_base + url_subpart\n",
    "\n",
    "        query_getAccessToken = {\"grant_type\":\"client_credentials\"}\n",
    "\n",
    "        headers_getAccessToken = {'Authorization': self.AuthorizationHeader}\n",
    "\n",
    "        # Get the web result for accesstoken\n",
    "        response = requests.get(url, headers=headers_getAccessToken, params=query_getAccessToken)\n",
    "\n",
    "        # Get the accesstoken from the web result\n",
    "        access_token = response.json()[\"access_token\"]\n",
    "\n",
    "        return access_token\n",
    "\n",
    "\n",
    "    def getFuelPrice(self):\n",
    "        '''\n",
    "        Returns all current fuel prices for all service stations. There may be restrictions on how often this API request can be made. It is recommended to execute this call in a separate api client as response can be over 2 mb. This API returns data for NSW.\n",
    "        '''\n",
    "        # Config url api prameters for getting fuel price\n",
    "        url_subpart = \"/FuelPriceCheck/v1/fuel/prices\"\n",
    "\n",
    "        url = self.url_base + url_subpart\n",
    "\n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {self.get_accesstoken()}',\n",
    "            'Content-Type': 'application/json; charset=utf-8',\n",
    "            'apikey': self.API_KEY,\n",
    "            'transactionid': FuelPriceCheckAPI.get_unique_transactionId(),\n",
    "            'requesttimestamp': FuelPriceCheckAPI.get_datetime_now()\n",
    "        }\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "\n",
    "    def getNewFuelPrice(self):\n",
    "        '''\n",
    "        Returns all new current prices that have been submitted since the last \"/fuelpricecheck/v1/fuel/prices\" or \"/fuelpricecheck/v1/fuel/prices/new\" request using the apikey on the current day. This API returns data for NSW.\n",
    "        '''\n",
    "        # Config url api prameters for getting fuel price\n",
    "        url_subpart = \"/FuelPriceCheck/v1/fuel/prices/new\"\n",
    "\n",
    "        url = self.url_base + url_subpart\n",
    "\n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {self.get_accesstoken()}',\n",
    "            'Content-Type': 'application/json; charset=utf-8',\n",
    "            'apikey': self.API_KEY,\n",
    "            'transactionid': FuelPriceCheckAPI.get_unique_transactionId(),\n",
    "            'requesttimestamp': FuelPriceCheckAPI.get_datetime_now()\n",
    "        }\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        return response\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "618d7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the class\n",
    "fuelpriceAPI = FuelPriceCheckAPI(API_KEY, AuthorizationHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de1f89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the API, simply called fuelpriceAPI.getNewFuelPrice() or fuelpriceAPI.getFuelPrice() depends on the usage\n",
    "responseFromGetFuelPrice = fuelpriceAPI.getFuelPrice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfce2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the result\n",
    "# print(json.dumps(responseFromGetFuelPrice.json(), indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01694ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the API, simply called fuelpriceAPI.getNewFuelPrice() or fuelpriceAPI.getFuelPrice() depends on the usage\n",
    "responseFromGetNewFuelPrice = fuelpriceAPI.getNewFuelPrice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "638d7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the result\n",
    "# print(json.dumps(responseFromGetNewFuelPrice.json(), indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686980c",
   "metadata": {},
   "source": [
    "2. Data Integration and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcba2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_display_fuel_data(input_file=\"integrated_fuel_data.csv\", output_file=\"integrated_fuel_data.csv\", column_width=70):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    # print(\"Missing Values per Column:\")\n",
    "    # print(missing_values)\n",
    "\n",
    "    # Drop rows with missing critical information\n",
    "    df = df.dropna(subset=[\"ServiceStationName\", \"FuelCode\", \"PriceUpdatedDate\", \"Latitude\", \"Longitude\", \"Price\"])\n",
    "\n",
    "    # Fill missing values in non-critical columns\n",
    "    df[\"Suburb\"].fillna(\"Unknown\", inplace=True)\n",
    "    df[\"Postcode\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "    # Convert FuelCode and Brand to categorical\n",
    "    df[\"FuelCode\"] = df[\"FuelCode\"].astype(\"category\")\n",
    "    df[\"Brand\"] = df[\"Brand\"].astype(\"category\")\n",
    "\n",
    "    # Ensure Latitude, Longitude, and Price are numeric\n",
    "    df[\"Latitude\"] = pd.to_numeric(df[\"Latitude\"], errors='coerce')\n",
    "    df[\"Longitude\"] = pd.to_numeric(df[\"Longitude\"], errors='coerce')\n",
    "    df[\"Price\"] = pd.to_numeric(df[\"Price\"], errors='coerce')\n",
    "\n",
    "    # Remove invalid coordinates or prices\n",
    "    df = df[\n",
    "        (df[\"Price\"] >= 0) &\n",
    "        (df[\"Latitude\"].between(-90, 90)) &\n",
    "        (df[\"Longitude\"].between(-180, 180))\n",
    "    ]\n",
    "\n",
    "    # Drop duplicate station-fuel-location combos\n",
    "    df = df.drop_duplicates(subset=[\"ServiceStationName\", \"FuelCode\", \"Latitude\", \"Longitude\"], keep=\"first\")\n",
    "\n",
    "    # Standardize text fields\n",
    "    df[\"Brand\"] = df[\"Brand\"].str.title()\n",
    "    df[\"Suburb\"] = df[\"Suburb\"].str.title()\n",
    "    df[\"FuelCode\"] = df[\"FuelCode\"].str.upper()\n",
    "\n",
    "    # Save cleaned data\n",
    "    df.to_csv(output_file, index=False)\n",
    "    # print(f\"Cleaned data saved as '{output_file}'.\")\n",
    "\n",
    "    # # Print cleaned data as aligned columns\n",
    "    # with open(output_file, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    #     reader = csv.DictReader(file)\n",
    "    #     headers = reader.fieldnames\n",
    "\n",
    "    #     print(\"\".join(h.ljust(column_width) for h in headers))\n",
    "    #     print(\"-\" * column_width * len(headers))\n",
    "\n",
    "    #     for row in reader:\n",
    "    #         print(\"\".join(str(row.get(field, \"\")).ljust(column_width) for field in headers))\n",
    "\n",
    "    # print(\"Cleaned DataFrame size:\", df.shape)\n",
    "\n",
    "    return df  \n",
    "\n",
    "def fetch_and_save_fuel_data(fuelpriceAPI, output_file=\"integrated_fuel_data.csv\", column_width=70):\n",
    "    # Step 1: Fetch data from the API\n",
    "    response = fuelpriceAPI.getFuelPrice()\n",
    "    data = response.json()\n",
    "\n",
    "    # Step 2: Create station mapping\n",
    "    station_map = {\n",
    "        station[\"code\"]: {\n",
    "            \"ServiceStationName\": station.get(\"name\"),\n",
    "            \"Address\": station.get(\"address\"),\n",
    "            \"Brand\": station.get(\"brand\"),\n",
    "            \"Latitude\": station.get(\"location\", {}).get(\"latitude\"),\n",
    "            \"Longitude\": station.get(\"location\", {}).get(\"longitude\")\n",
    "        }\n",
    "        for station in data.get(\"stations\", [])\n",
    "    }\n",
    "\n",
    "    # Step 3: Combine station info with prices\n",
    "    combined_data = []\n",
    "    for price_entry in data.get(\"prices\", []):\n",
    "        station_code = price_entry.get(\"stationcode\")\n",
    "        station_info = station_map.get(station_code)\n",
    "\n",
    "        if station_info:\n",
    "            full_address = station_info[\"Address\"]\n",
    "            try:\n",
    "                parts = full_address.split(\", \")\n",
    "                suburb_postcode = parts[-1].rsplit(\" \", 2)\n",
    "                suburb = suburb_postcode[0]\n",
    "                postcode = suburb_postcode[-1]\n",
    "            except Exception:\n",
    "                suburb, postcode = None, None\n",
    "\n",
    "            combined_data.append({\n",
    "                \"ServiceStationName\": station_info[\"ServiceStationName\"],\n",
    "                \"Address\": full_address,\n",
    "                \"Suburb\": suburb,\n",
    "                \"Postcode\": postcode,\n",
    "                \"Brand\": station_info[\"Brand\"],\n",
    "                \"FuelCode\": price_entry.get(\"fueltype\"),\n",
    "                \"Price\": price_entry.get(\"price\"),\n",
    "                \"PriceUpdatedDate\": price_entry.get(\"lastupdated\"),\n",
    "                \"Latitude\": station_info[\"Latitude\"],\n",
    "                \"Longitude\": station_info[\"Longitude\"]\n",
    "            })\n",
    "\n",
    "    # Step 4: Save to CSV\n",
    "    df = pd.DataFrame(combined_data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    # print(f\"Saved: {output_file}\")\n",
    "\n",
    "    # Step 5: Clean\n",
    "    cleaned_df = clean_and_display_fuel_data()\n",
    "\n",
    "\n",
    "def update_fuel_data(fuelpriceAPI, existing_file=\"integrated_fuel_data.csv\", output_file=\"integrated_fuel_data.csv\"):\n",
    "    # Step 1: Load existing data\n",
    "    existing_df = pd.read_csv(existing_file)\n",
    "\n",
    "    # Step 2: Fetch new data\n",
    "    response = fuelpriceAPI.getNewFuelPrice()\n",
    "    new_data_json = response.json()\n",
    "\n",
    "    # Step 3: Extract station mapping\n",
    "    station_map = {\n",
    "        station[\"code\"]: {\n",
    "            \"ServiceStationName\": station.get(\"name\"),\n",
    "            \"Latitude\": station.get(\"location\", {}).get(\"latitude\"),\n",
    "            \"Longitude\": station.get(\"location\", {}).get(\"longitude\")\n",
    "        }\n",
    "        for station in new_data_json.get(\"stations\", [])\n",
    "    }\n",
    "\n",
    "    # Step 4: Extract new fuel prices (subset of full dataset)\n",
    "    new_price_rows = []\n",
    "    for price in new_data_json.get(\"prices\", []):\n",
    "        station_code = price.get(\"stationcode\")\n",
    "        station_info = station_map.get(station_code)\n",
    "        if station_info:\n",
    "            new_price_rows.append({\n",
    "                \"ServiceStationName\": station_info[\"ServiceStationName\"],\n",
    "                \"FuelCode\": price.get(\"fueltype\"),\n",
    "                \"Latitude\": station_info[\"Latitude\"],\n",
    "                \"Longitude\": station_info[\"Longitude\"],\n",
    "                \"Price\": price.get(\"price\"),\n",
    "                \"PriceUpdatedDate\": price.get(\"lastupdated\")\n",
    "            })\n",
    "\n",
    "    new_df = pd.DataFrame(new_price_rows)\n",
    "\n",
    "    if new_df.empty:\n",
    "        print(\"No updates found in new data.\")\n",
    "        return existing_df\n",
    "\n",
    "    # Step 5: Merge to update only matching entries\n",
    "    updated_df = pd.merge(\n",
    "        existing_df,\n",
    "        new_df,\n",
    "        on=[\"FuelCode\", \"Latitude\", \"Longitude\"],\n",
    "        how=\"left\",\n",
    "        suffixes=('', '_new')\n",
    "    )\n",
    "\n",
    "    # Step 6: Replace old values only if new ones are provided\n",
    "    updated_df[\"Price\"] = updated_df[\"Price_new\"].combine_first(updated_df[\"Price\"])\n",
    "    updated_df[\"PriceUpdatedDate\"] = updated_df[\"PriceUpdatedDate_new\"].combine_first(updated_df[\"PriceUpdatedDate\"])\n",
    "    updated_df.drop(columns=[\"Price_new\", \"PriceUpdatedDate_new\"], inplace=True)\n",
    "\n",
    "    # Step 7: Save updated file\n",
    "    updated_df.to_csv(output_file, index=False)\n",
    "    # print(f\"Updated {new_df.shape[0]} fuel price entries.\")\n",
    "    # print(f\"Saved updated data to '{output_file}'.\")\n",
    "\n",
    "    return updated_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80e9ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junjun\\AppData\\Local\\Temp\\ipykernel_24724\\2669243978.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Suburb\"].fillna(\"Unknown\", inplace=True)\n",
      "C:\\Users\\junjun\\AppData\\Local\\Temp\\ipykernel_24724\\2669243978.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Postcode\"].fillna(\"Unknown\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "fetch_and_save_fuel_data(fuelpriceAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6722e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No updates found in new data.\n"
     ]
    }
   ],
   "source": [
    "updated_df = update_fuel_data(fuelpriceAPI)\n",
    "\n",
    "# # Print cleaned data as aligned columns\n",
    "# with open('integrated_fuel_data.csv', mode=\"r\", encoding=\"utf-8\") as file:\n",
    "#     reader = csv.DictReader(file)\n",
    "#     headers = reader.fieldnames\n",
    "\n",
    "#     print(\"\".join(h.ljust(70) for h in headers))\n",
    "#     print(\"-\" * 70 * len(headers))\n",
    "\n",
    "#     for row in reader:\n",
    "#         print(\"\".join(str(row.get(field, \"\")).ljust(70) for field in headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c152b2d",
   "metadata": {},
   "source": [
    "3. Data Publishing via MQTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4399d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Publishing via MQTT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b7ea0-ac40-40a7-953f-e207d96c96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "def on_connect(client, userdata, connect_flags, reason_code, properties):\n",
    "    print(\"Connected with result code\", str(reason_code))\n",
    "    # Subscribe as soon as we connect\n",
    "    client.subscribe(\"COMP5339/Assignment02/Group07/FuelPrice\")\n",
    "\n",
    "def on_message(client, userdata, msg):\n",
    "    print(json.loads(msg.payload))\n",
    "\n",
    "def publish_data():\n",
    "    # 1. Retrieve cleaned data\n",
    "    clean_data = pd.read_csv(\"integrated_fuel_data.csv\")\n",
    "    \n",
    "    # 2. Create client and attach callbacks\n",
    "    client = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n",
    "    client.on_connect = on_connect\n",
    "    client.on_message = on_message\n",
    "    \n",
    "    # 3. Connect to broker\n",
    "    client.connect(\"broker.hivemq.com\", 1883, keepalive=60)\n",
    "    \n",
    "    # 4. Start the network loop in a background thread\n",
    "    client.loop_start()\n",
    "    \n",
    "    # 5. Publish periodically\n",
    "    for row in clean_data.itertuples():\n",
    "    \n",
    "        data = {\n",
    "            \"Index\": row.Index, \n",
    "            \"ServiceStationName\": row.ServiceStationName,\n",
    "            \"Address\": row.Address, \n",
    "            \"Suburb\": row.Suburb, \n",
    "            \"Postcode\": row.Postcode, \n",
    "            \"Brand\": row.Brand, \n",
    "            \"FuelCode\": row.FuelCode, \n",
    "            \"Price\": row.Price, \n",
    "            \"PriceUpdatedDate\": row.PriceUpdatedDate, \n",
    "            \"Latitude\": row.Latitude, \n",
    "            \"Longitude\": row.Longitude\n",
    "        }\n",
    "    \n",
    "        client.publish(\"COMP5339/Assignment02/Group07/FuelPrice\", json.dumps(data), qos=2)\n",
    "    \n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    # 6. Clean up\n",
    "    client.loop_stop()\n",
    "    client.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4be25ba-5e6e-4436-8200-28f0c25fa51e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpublish_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 20\u001b[0m, in \u001b[0;36mpublish_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m client\u001b[38;5;241m.\u001b[39mon_message \u001b[38;5;241m=\u001b[39m on_message\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 3. Connect to broker\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m172.17.34.107\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1883\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepalive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 4. Start the network loop in a background thread\u001b[39;00m\n\u001b[0;32m     23\u001b[0m client\u001b[38;5;241m.\u001b[39mloop_start()\n",
      "File \u001b[1;32md:\\SystemProgramFiles\\anaconda\\envs\\COMP5310A2\\Lib\\site-packages\\paho\\mqtt\\client.py:1435\u001b[0m, in \u001b[0;36mClient.connect\u001b[1;34m(self, host, port, keepalive, bind_address, bind_port, clean_start, properties)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProperties only apply to MQTT V5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect_async(host, port, keepalive,\n\u001b[0;32m   1434\u001b[0m                    bind_address, bind_port, clean_start, properties)\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\SystemProgramFiles\\anaconda\\envs\\COMP5310A2\\Lib\\site-packages\\paho\\mqtt\\client.py:1598\u001b[0m, in \u001b[0;36mClient.reconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1595\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_exceptions:\n\u001b[0;32m   1596\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1598\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msetblocking(\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_write \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\SystemProgramFiles\\anaconda\\envs\\COMP5310A2\\Lib\\site-packages\\paho\\mqtt\\client.py:4609\u001b[0m, in \u001b[0;36mClient._create_socket\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4607\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_unix_socket_connection()\n\u001b[0;32m   4608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4609\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_socket_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl:\n\u001b[0;32m   4612\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_wrap_socket(sock)\n",
      "File \u001b[1;32md:\\SystemProgramFiles\\anaconda\\envs\\COMP5310A2\\Lib\\site-packages\\paho\\mqtt\\client.py:4640\u001b[0m, in \u001b[0;36mClient._create_socket_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m socks\u001b[38;5;241m.\u001b[39mcreate_connection(addr, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_timeout, source_address\u001b[38;5;241m=\u001b[39msource, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mproxy)\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\SystemProgramFiles\\anaconda\\envs\\COMP5310A2\\Lib\\socket.py:865\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[1;32m--> 865\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionGroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_connection failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exceptions)\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32md:\\SystemProgramFiles\\anaconda\\envs\\COMP5310A2\\Lib\\socket.py:850\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m    849\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 850\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m    852\u001b[0m exceptions\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[1;31mTimeoutError\u001b[0m: timed out"
     ]
    }
   ],
   "source": [
    "publish_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c160c5df",
   "metadata": {},
   "source": [
    "4. Data Subscribing and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Subscribing and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776c5c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2e3fc",
   "metadata": {},
   "source": [
    "5. Continuous Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f943b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Continuous Execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP5310A2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
